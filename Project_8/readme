# Что было зделанно:

1. Был произведен EDA для работы с Catboost.

    1. Добавлены 2 новых числовых признака ('enginePower_', 'enginePower_/mileage')
    2. Пропуски в числовых признаках заменены средним значением.
    3. Числовые значения нормализированы с помощью MinMaxScaler.
    4. Для категориальных признаков применен One-Hot Encoding.
    5. Распределения числовых признаков имеют правые или левые хвосты поэтому прологарифмированы.
    6. Целевая переменная тоже прологарифмирована.
    
    Результаты работы Catboost - TEST mape: 11.03%



2. Был произведен EDA для работы с Нейронной сетью.

    1. Добавлены признаки ('mile_year', '4WD', 'xDrive').
    2. Из признака Владение удалена информация об месяцах.
    3. В столбце engineDisplacement Заменено значение undefined LTR на моду 2.0 LTR.
    4. вместо MinMaxScaler используем RobustScaler.
    5. Не логарифмируем числовые признаки. (Иначе алгоритм предсказывает одно и тоже значение для всех обьектов)




3. Настройка Сети для работы с табличными данными.

    1. Уменьшен Dropout после второго слоя.
    2. Вместо Adam выбран оптимизатор RMSprop.
    
    TEST mape: 10.90%



3. Настройка Сети NLP + Multiple Inputs.

    1. С помошью MorphAnalyzer приводим слова из столбца description к нормальному виду.
    2. Далее с помощью nltk.download("stopwords") и Tokenizer создаем токены текста.
    3. После просмотра получившихся токенов удаляем токены несуществующих слов.
    4. Опять вместо Adam выбиваем RMSprop с lr = 0.001.
    
    TEST mape: 11.17%


4. Усредняем предсказания сети для работы с табличными данными, NLP + Multiple Inputs и Catboost.

   Получаем значение метрики TEST mape: 10.44%.



# Что еще можно было зделать:

1. Не хватило времени для экспериментов с добавлением сверточной сети, но можно было попробовать разные виды аугментаций.


# Выводы

1. Нейронные сети при работе с табличными данными справляються не хуже чем алгоритмы класического ML (по крайней мере в этом случае) 

2. Рекурентные сети хорошо справляються с задачей обработки текста для предсказаний.

3. С помощью Blending можно улучшить результат.




### Лучший score на Kaggle 11.32435

